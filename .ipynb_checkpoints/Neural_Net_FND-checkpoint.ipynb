{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "SEZlOM84EeEA",
   "metadata": {
    "id": "SEZlOM84EeEA"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/gerakys/PyhtonProject_DMTA/blob/main/Neural_Net_FND.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lQ7LImVTDHel",
   "metadata": {
    "id": "lQ7LImVTDHel"
   },
   "source": [
    "# Fake News Detection using Neural Networks\n",
    "---\n",
    "In this notebook, our mission is to construct a robust neural network for discerning the authenticity of news articles. The approach will be as follows:\n",
    "\n",
    "* Data Exploration and Cleansing\n",
    "* Data Selection and Encoding\n",
    "* Text Preprocessing\n",
    "* Neural Network Architecture\n",
    "* Model Training and Evalutation\n",
    "* Real-time Prediction\n",
    "\n",
    "An example of a real and fake news are shown below.\n",
    "\n",
    "<img src='notebook_ims/real_fake_example.png' width=50% height=80% />\n",
    "\n",
    "Our dataset comprises a collection of news articles labeled as either real or fake. We meticulously explore and preprocess this data to ensure our neural network receives high-quality inputs for training and evaluation.\n",
    "\n",
    "Let's Begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521864a9",
   "metadata": {
    "id": "521864a9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382b485",
   "metadata": {},
   "source": [
    "## Load in and Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf2a31d",
   "metadata": {
    "id": "6cf2a31d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"data/fake_or_real_news.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd2456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check for any missing values\n",
    "data.isnull().sum() # there are not\n",
    "# We see if our dataset is balanced\n",
    "data['label'].value_counts() # it is!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d40a20",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The initial step in constructing our neural network is preparing the data for effective input. As we intend to incorporate a word-embedding layer, the following steps are undertaken:\n",
    "\n",
    "1. **Encoding Words and Labels:**\n",
    "   - Encode each word in the news articles as an integer.\n",
    "   - Encode sentiment labels, representing real as 1 and false as 0.\n",
    "\n",
    "2. **Tokenization:**\n",
    "   - Utilize the `Tokenizer` class to create a vocabulary of unique words.\n",
    "   - Fit the tokenizer on the dataset to associate each word with a unique integer.\n",
    "\n",
    "3. **Text to Sequences:**\n",
    "   - Transform the textual data into sequences of integers using the fitted tokenizer.\n",
    "   - This step helps in numerical representation of the news headlines.\n",
    "\n",
    "4. **Padding Sequences:**\n",
    "   - Apply padding to the sequences to ensure uniform length across all data points.\n",
    "   - Pad sequences with zeros to match the desired length, enhancing model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64623ac6",
   "metadata": {
    "id": "64623ac6"
   },
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "x = np.array(data[\"title\"])\n",
    "y = np.array(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "883fdbe7",
   "metadata": {
    "id": "883fdbe7"
   },
   "outputs": [],
   "source": [
    "# Convert labels to numerical format\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c859c773",
   "metadata": {
    "id": "c859c773"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ') # definiamo il nostro tokenizer\n",
    "tokenizer.fit_on_texts(x) # fittiamo sui nostri dati il tokenizer\n",
    "x = tokenizer.texts_to_sequences(x) #trasformazione del testo in sequenze di interi\n",
    "x = pad_sequences(x) # padding per uniformare le sequenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3dc7150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 1\n",
      "to: 2\n",
      "in: 3\n",
      "of: 4\n",
      "trump: 5\n",
      "for: 6\n",
      "on: 7\n",
      "a: 8\n",
      "and: 9\n",
      "is: 10\n",
      "clinton: 11\n",
      "hillary: 12\n",
      "with: 13\n",
      "obama: 14\n",
      "new: 15\n",
      "by: 16\n",
      "as: 17\n",
      "donald: 18\n",
      "from: 19\n",
      "at: 20\n"
     ]
    }
   ],
   "source": [
    "# we take a look at our vocabulary\n",
    "indice_parole = tokenizer.word_index\n",
    "for word, index in list(indice_parole.items())[:20]:\n",
    "    print(f\"{word}: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4758741",
   "metadata": {},
   "source": [
    "## Let's Build our Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5adcb3",
   "metadata": {},
   "source": [
    "First step will be splitting the data into training and testing sets.\n",
    "This is a crucial step in preparing our dataset for training and evaluating the model.\n",
    "Using the train_test_split function from sklearn, we divide our data into training and testing sets.\n",
    "We allocate 80% of the data for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412acb1c",
   "metadata": {
    "id": "412acb1c"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5c80a",
   "metadata": {},
   "source": [
    "The layers are as follows:\n",
    "* An embedding layer that converts our word tokens (integers) into embeddings of a specific size.\n",
    "* A dropout layer to prevent overfitting by deactivating 20% of the previous embeddings.\n",
    "* An LSTM layer defined by a hidden_state size and number of layers\n",
    "* A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
    "* A sigmoid activation layer which turns all outputs into a value 0-1; return only the last sigmoid output as the output of this network.\n",
    "* Compile the model with binary crossentropy loss, adam optimizer, and accuracy metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "284d10b2",
   "metadata": {
    "id": "284d10b2"
   },
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential() # creiamo un modello sequenziale, strato per strati\n",
    "model.add(Embedding(max_words, 128, input_length=x.shape[1])) # layer di embedding\n",
    "model.add(SpatialDropout1D(0.2)) # per prevenire l'overfitting si disattivano il 20% dei precedenti embeddings\n",
    "model.add(LSTM(100)) # Tipo di RNN. il valore tra parentesi indica il numero di nodi\n",
    "model.add(Dense(1, activation='sigmoid')) # layer \"fully connected\" denso che termina il modello con un singolo neurone \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # funzione di loss, di ottimizzazione e metrica di valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ade537e8",
   "metadata": {
    "id": "ade537e8",
    "outputId": "ab1531cf-81b8-4a96-b2b6-6a44ff0a831a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "127/127 [==============================] - 7s 58ms/step - loss: 0.1022 - accuracy: 0.9640 - val_loss: 0.6158 - val_accuracy: 0.7978\n",
      "Epoch 2/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.7298 - val_accuracy: 0.7870\n",
      "Epoch 3/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0684 - accuracy: 0.9761 - val_loss: 0.7146 - val_accuracy: 0.8047\n",
      "Epoch 4/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.8344 - val_accuracy: 0.8047\n",
      "Epoch 5/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.8967 - val_accuracy: 0.7949\n",
      "Epoch 6/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.9992 - val_accuracy: 0.7890\n",
      "Epoch 7/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 1.0876 - val_accuracy: 0.7939\n",
      "Epoch 8/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 1.2522 - val_accuracy: 0.7899\n",
      "Epoch 9/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 1.1463 - val_accuracy: 0.7909\n",
      "Epoch 10/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 1.2619 - val_accuracy: 0.7909\n",
      "Epoch 11/60\n",
      "127/127 [==============================] - 7s 54ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 1.3561 - val_accuracy: 0.7919\n",
      "Epoch 12/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 1.6908 - val_accuracy: 0.7357\n",
      "Epoch 13/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 1.0432 - val_accuracy: 0.7899\n",
      "Epoch 14/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 1.2073 - val_accuracy: 0.7860\n",
      "Epoch 15/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.2898 - val_accuracy: 0.7870\n",
      "Epoch 16/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.3322 - val_accuracy: 0.7899\n",
      "Epoch 17/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.3812 - val_accuracy: 0.7870\n",
      "Epoch 18/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 7.7848e-04 - accuracy: 0.9998 - val_loss: 1.4123 - val_accuracy: 0.7870\n",
      "Epoch 19/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 9.2525e-04 - accuracy: 0.9998 - val_loss: 1.4429 - val_accuracy: 0.7880\n",
      "Epoch 20/60\n",
      "127/127 [==============================] - 7s 58ms/step - loss: 8.1592e-04 - accuracy: 0.9998 - val_loss: 1.4896 - val_accuracy: 0.7830\n",
      "Epoch 21/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 8.4801e-04 - accuracy: 0.9998 - val_loss: 1.5110 - val_accuracy: 0.7929\n",
      "Epoch 22/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 6.1689e-04 - accuracy: 0.9998 - val_loss: 1.5255 - val_accuracy: 0.7909\n",
      "Epoch 23/60\n",
      "127/127 [==============================] - 7s 58ms/step - loss: 4.5580e-04 - accuracy: 1.0000 - val_loss: 1.5728 - val_accuracy: 0.7899\n",
      "Epoch 24/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 4.7214e-04 - accuracy: 1.0000 - val_loss: 1.5872 - val_accuracy: 0.7890\n",
      "Epoch 25/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 3.6704e-04 - accuracy: 1.0000 - val_loss: 1.6239 - val_accuracy: 0.7870\n",
      "Epoch 26/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 2.7083e-04 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.7870\n",
      "Epoch 27/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 3.4067e-04 - accuracy: 1.0000 - val_loss: 1.7162 - val_accuracy: 0.7959\n",
      "Epoch 28/60\n",
      "127/127 [==============================] - 7s 54ms/step - loss: 2.2405e-04 - accuracy: 1.0000 - val_loss: 1.7310 - val_accuracy: 0.7899\n",
      "Epoch 29/60\n",
      "127/127 [==============================] - 7s 54ms/step - loss: 1.9656e-04 - accuracy: 1.0000 - val_loss: 1.7599 - val_accuracy: 0.7909\n",
      "Epoch 30/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 1.7705e-04 - accuracy: 1.0000 - val_loss: 1.8054 - val_accuracy: 0.7939\n",
      "Epoch 31/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 2.4224e-04 - accuracy: 1.0000 - val_loss: 1.7988 - val_accuracy: 0.7890\n",
      "Epoch 32/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 1.6682e-04 - accuracy: 1.0000 - val_loss: 1.8064 - val_accuracy: 0.7899\n",
      "Epoch 33/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 1.4143e-04 - accuracy: 1.0000 - val_loss: 1.8595 - val_accuracy: 0.7899\n",
      "Epoch 34/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 1.1863e-04 - accuracy: 1.0000 - val_loss: 1.9118 - val_accuracy: 0.7909\n",
      "Epoch 35/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 9.6968e-05 - accuracy: 1.0000 - val_loss: 1.9174 - val_accuracy: 0.7840\n",
      "Epoch 36/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 7.9114e-05 - accuracy: 1.0000 - val_loss: 1.9650 - val_accuracy: 0.7850\n",
      "Epoch 37/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 6.7522e-05 - accuracy: 1.0000 - val_loss: 2.0107 - val_accuracy: 0.7899\n",
      "Epoch 38/60\n",
      "127/127 [==============================] - 7s 58ms/step - loss: 8.2661e-05 - accuracy: 1.0000 - val_loss: 2.0458 - val_accuracy: 0.7860\n",
      "Epoch 39/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 1.3447 - val_accuracy: 0.7712\n",
      "Epoch 40/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 0.0242 - accuracy: 0.9896 - val_loss: 1.1514 - val_accuracy: 0.7890\n",
      "Epoch 41/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 1.4568 - val_accuracy: 0.7919\n",
      "Epoch 42/60\n",
      "127/127 [==============================] - 7s 57ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.4150 - val_accuracy: 0.7870\n",
      "Epoch 43/60\n",
      "127/127 [==============================] - 7s 58ms/step - loss: 6.5133e-04 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.7939\n",
      "Epoch 44/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 3.7906e-04 - accuracy: 1.0000 - val_loss: 1.5440 - val_accuracy: 0.7949\n",
      "Epoch 45/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 3.4397e-04 - accuracy: 1.0000 - val_loss: 1.5873 - val_accuracy: 0.7949\n",
      "Epoch 46/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 2.9005e-04 - accuracy: 1.0000 - val_loss: 1.6217 - val_accuracy: 0.7929\n",
      "Epoch 47/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 2.0773e-04 - accuracy: 1.0000 - val_loss: 1.6618 - val_accuracy: 0.7949\n",
      "Epoch 48/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 2.7456e-04 - accuracy: 1.0000 - val_loss: 1.6809 - val_accuracy: 0.7899\n",
      "Epoch 49/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 1.8760e-04 - accuracy: 1.0000 - val_loss: 1.7110 - val_accuracy: 0.7919\n",
      "Epoch 50/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 1.3412e-04 - accuracy: 1.0000 - val_loss: 1.7468 - val_accuracy: 0.7929\n",
      "Epoch 51/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 2.3501e-04 - accuracy: 1.0000 - val_loss: 1.7550 - val_accuracy: 0.7899\n",
      "Epoch 52/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 1.6571e-04 - accuracy: 1.0000 - val_loss: 1.7946 - val_accuracy: 0.7939\n",
      "Epoch 53/60\n",
      "127/127 [==============================] - 7s 54ms/step - loss: 1.1611e-04 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.7959\n",
      "Epoch 54/60\n",
      "127/127 [==============================] - 7s 55ms/step - loss: 8.6164e-05 - accuracy: 1.0000 - val_loss: 1.8247 - val_accuracy: 0.7929\n",
      "Epoch 55/60\n",
      "127/127 [==============================] - 7s 54ms/step - loss: 1.0221e-04 - accuracy: 1.0000 - val_loss: 1.8592 - val_accuracy: 0.7919\n",
      "Epoch 56/60\n",
      "127/127 [==============================] - 7s 54ms/step - loss: 7.6907e-05 - accuracy: 1.0000 - val_loss: 1.8840 - val_accuracy: 0.7909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "127/127 [==============================] - 8s 61ms/step - loss: 6.6325e-05 - accuracy: 1.0000 - val_loss: 1.9113 - val_accuracy: 0.7909\n",
      "Epoch 58/60\n",
      "127/127 [==============================] - 8s 63ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 1.1569 - val_accuracy: 0.7821\n",
      "Epoch 59/60\n",
      "127/127 [==============================] - 8s 61ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 1.3160 - val_accuracy: 0.7840\n",
      "Epoch 60/60\n",
      "127/127 [==============================] - 7s 56ms/step - loss: 7.2433e-04 - accuracy: 1.0000 - val_loss: 1.4650 - val_accuracy: 0.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2735f4975b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 32 # provare a cambiare \n",
    "epochs = 60 # prova 60\n",
    "model.fit(xtrain, ytrain, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e52f99a9",
   "metadata": {
    "id": "e52f99a9",
    "outputId": "dd1562d4-9156-4ed1-b0df-1581e9871424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 18ms/step - loss: 1.5687 - accuracy: 0.7790\n",
      "Model Accuracy: 0.78\n",
      "Model Loss: 1.5687307119369507\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "loss, accuracy = model.evaluate(xtest, ytest)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Model Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1b94dc6",
   "metadata": {
    "id": "d1b94dc6",
    "outputId": "25a2967d-20c9-4403-d39a-cc68cb8e098b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type News title here: Will Biden ever stand up to Benjamin Netanyahu? Don’t bet on it\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "Predicted Label: Real (Probability: 0.00)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on a sample news headline\n",
    "news_headline = input(\"Type News title here: \")\n",
    "headline_seq = tokenizer.texts_to_sequences(news_headline)\n",
    "headline_padded = pad_sequences(headline_seq, maxlen=x.shape[1])\n",
    "result = model.predict(headline_padded)[0][0]\n",
    "predicted_label = \"Real\" if result < 0.5 else \"Fake\"\n",
    "print(f\"Predicted Label: {predicted_label} (Probability: {result:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfee1a",
   "metadata": {
    "id": "0fcfee1a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
